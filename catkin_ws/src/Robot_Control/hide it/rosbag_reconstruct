#! /usr/bin/env python
import pyrealsense2 as rs
import numpy as np
import cv2
from stereo_matching import *
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import rospy
import std_msgs
from sensor_msgs.msg import PointCloud2
import sensor_msgs.point_cloud2 as pcl2

intrinsic_matrix = np.asarray([[380.16, 0 , 321.331],[0, 380.16, 235.967], [0,0,1]])
extrinsic_matrix1 = np.asarray([[1,0,0,0],[0,1,0,0],[0,0,1,0]])
extrinsic_matrix2 = np.asarray([[1,0,0,0.0499],[0,1,0,0],[0,0,1,0]])
projection_matrix1 = np.matmul(intrinsic_matrix,extrinsic_matrix1)
projection_matrix2 = np.matmul(intrinsic_matrix,extrinsic_matrix2)
points = rs.points()
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.infrared, 1, 640, 480, rs.format.y8, 30)
config.enable_stream(rs.stream.infrared, 2, 640, 480, rs.format.y8, 30)
profile = pipeline.start(config)

def triangulate(C1, pts1, C2, pts2):
    A = np.zeros((4,4))
    for i in range(0,pts1.shape[0]):
        A[0,:] = C1[0,:] - pts1[i,0]*C1[2,:]
        A[1,:] = C1[1,:] - pts1[i,1]*C1[2,:]
        A[2,:] = C2[0,:] - pts2[i,0]*C2[2,:]
        A[3,:] = C2[1,:] - pts2[i,1]*C2[2,:]

        U,S,VT = np.linalg.svd(A)
        point = VT[-1,:]
        point = point/point[-1]
        point = list(point[:-1])
        if i == 0:
            points = [point]
        else:
            points.append(point)
            # points = np.vstack((points,point))
    return points

if __name__ == '__main__':
    rospy.init_node('Stereo_Reconstruction_Node')
    cloud_pub = rospy.Publisher('cloud_from_images', PointCloud2, queue_size = 10)
    try:
        while True:
            frames = pipeline.wait_for_frames()
            nir_lf_frame = frames.get_infrared_frame(1)
            nir_rg_frame = frames.get_infrared_frame(2)

            if not nir_lf_frame or not nir_rg_frame:
                continue
            nir_rg_image = np.asanyarray(nir_rg_frame.get_data())
            nir_lf_image = np.asanyarray(nir_lf_frame.get_data())

            kp1, kp2, matches = find_correspondences(nir_rg_image, nir_lf_image)

            points1 = []
            points2 = []
            # matches = matches[:100]
            for match in matches:
                points1.append(kp1[match.queryIdx].pt)
                points2.append(kp2[match.trainIdx].pt)

            points1 = np.asarray(points1).astype('int')
            points2 = np.asarray(points2).astype('int')

            points = triangulate(projection_matrix1,np.asarray(points1), projection_matrix2, np.asarray(points2))
            image=np.hstack((nir_lf_image,nir_rg_image))
            img4= cv2.drawMatches(nir_rg_image,kp1,nir_lf_image,kp2,matches, flags=2, outImg = image)

            print(points)
            header = std_msgs.msg.Header()
            header.stamp = rospy.Time.now()
            header.frame_id = 'map'
            cloud = pcl2.create_cloud_xyz32(header, points)
            cloud_pub.publish(cloud)

            cv2.namedWindow('NIR images (left, right)', cv2.WINDOW_AUTOSIZE)
            cv2.imshow('IR Example2', img4)
            key = cv2.waitKey(1)
            # print("[Average Depth]: ", sum(points[:,2])/len(points[:,2]))
            if key & 0xFF == ord('q') or key == 27:
                cv2.destroyAllWindows()
                break

    finally:
        pipeline.stop()
